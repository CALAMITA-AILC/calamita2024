[
    {"TASK": "abricot_abs", "METRIC": "pearson", "RESULT_LLAMA": 0.2908569687822414, "RESULT_ANITA": 0.49656702564086047},
    {"TASK": "abricot_inc", "METRIC": "pearson", "RESULT_LLAMA": 0.17995611105630827, "RESULT_ANITA": 0.13833157094574233},
    {"TASK": "amelia-arg-component-fewshot", "METRIC": "f1", "RESULT_LLAMA": 0.3294590036818332, "RESULT_ANITA": 0.3539600269076482},
    {"TASK": "amelia-arg-component-zeroshot", "METRIC": "f1", "RESULT_LLAMA": 0.21276489217697014, "RESULT_ANITA": 0.3696736469239985},
    {"TASK": "amelia-arg-premisetype-fewshot", "METRIC": "f1", "RESULT_LLAMA": 0.739723754147546, "RESULT_ANITA": 0.7953404032860343},
    {"TASK": "amelia-arg-premisetype-zeroshot", "METRIC": "f1", "RESULT_LLAMA": 0.39095695582205003, "RESULT_ANITA": 0.7115364327063769},
    {"TASK": "amelia-arg-scheme-fewshot", "METRIC": "f1", "RESULT_LLAMA": 0.35341596946742015, "RESULT_ANITA": 0.4967036183998685},
    {"TASK": "amelia-arg-scheme-zeroshot", "METRIC": "f1", "RESULT_LLAMA": 0.30847279538147243, "RESULT_ANITA": 0.36399881034088316},
    {"TASK": "ami_2020_aggressiveness", "METRIC": "f1", "RESULT_LLAMA": 0.6043531519577608, "RESULT_ANITA": 0.48390898255900794},
    {"TASK": "ami_2020_misogyny", "METRIC": "f1", "RESULT_LLAMA": 0.7264848403202169, "RESULT_ANITA": 0.7272727272727273},
    {"TASK": "arc_challenge_ita", "METRIC": "acc", "RESULT_LLAMA": 0.4112627986348123, "RESULT_ANITA": 0.5341296928327645},
    {"TASK": "arc_easy_ita", "METRIC": "acc", "RESULT_LLAMA": 0.640993265993266, "RESULT_ANITA": 0.7171717171717171},
    {"TASK": "beep", "METRIC": "acc", "RESULT_LLAMA": 0.6482876712328767, "RESULT_ANITA": 0.6243150684931507},
    {"TASK": "belebele_ita", "METRIC": "acc", "RESULT_LLAMA": 0.8577777777777778, "RESULT_ANITA": 0.8377777777777777},
    {"TASK": "blm_agr1_0shots", "METRIC": "f1", "RESULT_LLAMA": 0.10176824185248454, "RESULT_ANITA": 0.1405335507256354},
    {"TASK": "blm_agr1_1shots", "METRIC": "f1", "RESULT_LLAMA": 0.25981139401067327, "RESULT_ANITA": 0.18409660865675453},
    {"TASK": "blm_agr2_0shots", "METRIC": "f1", "RESULT_LLAMA": 0.10579686199272331, "RESULT_ANITA": 0.19820170728673997},
    {"TASK": "blm_agr2_1shots", "METRIC": "f1", "RESULT_LLAMA": 0.2361151348809637, "RESULT_ANITA": 0.2988161930960832},
    {"TASK": "blm_caus1_0shots", "METRIC": "f1", "RESULT_LLAMA": 0.05077655826700318, "RESULT_ANITA": 0.04763617241010421},
    {"TASK": "blm_caus1_1shots", "METRIC": "f1", "RESULT_LLAMA": 0.130724815899494, "RESULT_ANITA": 0.08176935719678124},
    {"TASK": "blm_caus2_0shots", "METRIC": "f1", "RESULT_LLAMA": 0.05696211378404919, "RESULT_ANITA": 0.06715288355895183},
    {"TASK": "blm_caus2_1shots", "METRIC": "f1", "RESULT_LLAMA": 0.13108390415844468, "RESULT_ANITA": 0.12259124085699119},
    {"TASK": "blm_od1_0shots", "METRIC": "f1", "RESULT_LLAMA": 0.06428726115074491, "RESULT_ANITA": 0.057766086539098815},
    {"TASK": "blm_od1_1shots", "METRIC": "f1", "RESULT_LLAMA": 0.12549810096947103, "RESULT_ANITA": 0.08686878355214397},
    {"TASK": "blm_od2_0shots", "METRIC": "f1", "RESULT_LLAMA": 0.06105883355813455, "RESULT_ANITA": 0.05662657526892521},
    {"TASK": "blm_od2_1shots", "METRIC": "f1", "RESULT_LLAMA": 0.1154221686931689, "RESULT_ANITA": 0.10120225478502334},
    {"TASK": "conflict_detect", "METRIC": "acc", "RESULT_LLAMA": 0.3723849372384937, "RESULT_ANITA": 0.34309623430962344},
    {"TASK": "ecwca-hint", "METRIC": "words_avg_f1", "RESULT_LLAMA": 0.09186258301304483, "RESULT_ANITA": 0.07578980946850902},
    {"TASK": "ecwca-no-hint", "METRIC": "words_avg_f1", "RESULT_LLAMA": 0.10368120925048943, "RESULT_ANITA": 0.0635633638604444},
    {"TASK": "gattina-ansa", "METRIC": "sbert_score", "RESULT_LLAMA": 0.3264906958955771, "RESULT_ANITA": 0.17417554643821273},
    {"TASK": "gattina-galileo", "METRIC": "sbert_score", "RESULT_LLAMA": 0.21791279301643013, "RESULT_ANITA": 0.20502314949521763},
    {"TASK": "geese_dummy", "METRIC": "acc", "RESULT_LLAMA": 0.48625, "RESULT_ANITA": 0.50375},
    {"TASK": "geese_human", "METRIC": "acc", "RESULT_LLAMA": 0.5425, "RESULT_ANITA": 0.56375},
    {"TASK": "geese_llama3", "METRIC": "acc", "RESULT_LLAMA": 0.665, "RESULT_ANITA": 0.6225},
    {"TASK": "geese_noexp", "METRIC": "acc", "RESULT_LLAMA": 0.4625, "RESULT_ANITA": 0.37625},
    {"TASK": "gfg_task_1_1", "METRIC": "bert_f1", "RESULT_LLAMA": 0.9163784459233284, "RESULT_ANITA": 0.4746150076389313},
    {"TASK": "gfg_task_1_2", "METRIC": "bert_f1", "RESULT_LLAMA": 0.26739147770629834, "RESULT_ANITA": 0.287073515599058},
    {"TASK": "gfg_task_2_1", "METRIC": "acc_gente", "RESULT_LLAMA": 0.6830357142857143, "RESULT_ANITA": 0.6651785714285714},
    {"TASK": "gfg_task_2_2", "METRIC": "cwa", "RESULT_LLAMA": 52.7127569220316, "RESULT_ANITA": 53.89955268671079},
    {"TASK": "gfg_task_2_3", "METRIC": "acc_gente", "RESULT_LLAMA": 0.31466666666666665, "RESULT_ANITA": 0.49866666666666665},
    {"TASK": "gfg_task_3_1", "METRIC": "cwa", "RESULT_LLAMA": 41.66822376988845, "RESULT_ANITA": 35.68484230791005},
    {"TASK": "gfg_task_3_2", "METRIC": "acc_gente", "RESULT_LLAMA": 0.6093333333333333, "RESULT_ANITA": 0.5566666666666666},
    {"TASK": "haspeede2_hs", "METRIC": "f1", "RESULT_LLAMA": 0.6991982842062379, "RESULT_ANITA": 0.6998010187451045},
    {"TASK": "haspeede2_stereo", "METRIC": "f1", "RESULT_LLAMA": 0.6037287968283951, "RESULT_ANITA": 0.624441393100974},
    {"TASK": "hatecheck_ita", "METRIC": "f1", "RESULT_LLAMA": 0.825468982535432, "RESULT_ANITA": 0.8117266439604165},
    {"TASK": "hellaswag_ita", "METRIC": "acc", "RESULT_LLAMA": 0.4532961561441944, "RESULT_ANITA": 0.5105556662019518},
    {"TASK": "invalsi_ita", "METRIC": "acc", "RESULT_LLAMA": 0.7135183527305282, "RESULT_ANITA": 0.7090420769919427},
    {"TASK": "invalsi_ita_binarie", "METRIC": "acc", "RESULT_LLAMA": 0.6071428571428571, "RESULT_ANITA": 0.65},
    {"TASK": "invalsi_ita_multipla", "METRIC": "acc", "RESULT_LLAMA": 0.7287615148413511, "RESULT_ANITA": 0.7175025588536336},
    {"TASK": "invalsi_mate", "METRIC": "acc", "RESULT_LLAMA": 0.5075, "RESULT_ANITA": 0.4725},
    {"TASK": "invalsi_mate_multipla", "METRIC": "acc", "RESULT_LLAMA": 0.45491803278688525, "RESULT_ANITA": 0.4139344262295082},
    {"TASK": "invalsi_mate_numero", "METRIC": "acc", "RESULT_LLAMA": 0.5882352941176471, "RESULT_ANITA": 0.5392156862745098},
    {"TASK": "invalsi_mate_verofalso", "METRIC": "acc", "RESULT_LLAMA": 0.5925925925925926, "RESULT_ANITA": 0.6111111111111112},
    {"TASK": "ironita_irony", "METRIC": "f1", "RESULT_LLAMA": 0.6741186970102633, "RESULT_ANITA": 0.6869456865349934},
    {"TASK": "ironita_sarcasm", "METRIC": "f1", "RESULT_LLAMA": 0.5178314988006253, "RESULT_ANITA": 0.4641951625148186},
    {"TASK": "ita-sense-gen-no-translation", "METRIC": "rougeBertScore", "RESULT_LLAMA": 0.31921862236515036, "RESULT_ANITA": 0.25854083584126464},
    {"TASK": "ita-sense-gen-with-translation", "METRIC": "rougeBertScore", "RESULT_LLAMA": 0.3192784120872682, "RESULT_ANITA": 0.2630987442843378},
    {"TASK": "ita-sense-ml-no-translation", "METRIC": "extract_answer", "RESULT_LLAMA": 0.41268803139306737, "RESULT_ANITA": 0.5120994113799869},
    {"TASK": "ita-sense-ml-with-translation", "METRIC": "extract_answer", "RESULT_LLAMA": 0.3856280855732309, "RESULT_ANITA": 0.4750411409764125},
    {"TASK": "itacola", "METRIC": "acc", "RESULT_LLAMA": 0.8246153846153846, "RESULT_ANITA": 0.6892307692307692},
    {"TASK": "multi-it-a", "METRIC": "acc", "RESULT_LLAMA": 0.6465721040189125, "RESULT_ANITA": 0.6211583924349882},
    {"TASK": "multi-it-c", "METRIC": "acc", "RESULT_LLAMA": 0.6623020762454714, "RESULT_ANITA": 0.6280964378321717},
    {"TASK": "news_sum_fanpage", "METRIC": "rouge1", "RESULT_LLAMA": 0.32841168208870886, "RESULT_ANITA": 0.30181000742312586},
    {"TASK": "news_sum_ilpost", "METRIC": "rouge1", "RESULT_LLAMA": 0.3200355367367411, "RESULT_ANITA": 0.28636010182549587},
    {"TASK": "pejorativITy-misoginy", "METRIC": "acc", "RESULT_LLAMA": 0.45916666666666667, "RESULT_ANITA": 0.67},
    {"TASK": "pejorativITy-misoginy-context", "METRIC": "acc", "RESULT_LLAMA": 0.8158333333333333, "RESULT_ANITA": 0.7866666666666666},
    {"TASK": "pejorativITy-standard", "METRIC": "acc", "RESULT_LLAMA": 0.44166666666666665, "RESULT_ANITA": 0.51},
    {"TASK": "perse_task_0", "METRIC": "f1", "RESULT_LLAMA": 0.4953869281153722, "RESULT_ANITA": 0.3238903867047604},
    {"TASK": "perse_task_1", "METRIC": "f1", "RESULT_LLAMA": 0.4973010010528603, "RESULT_ANITA": 0.24787574234810417},
    {"TASK": "perse_task_2", "METRIC": "f1", "RESULT_LLAMA": 0.49703006640638037, "RESULT_ANITA": 0.26859912052409585},
    {"TASK": "perse_task_3", "METRIC": "f1", "RESULT_LLAMA": 0.49607149132715816, "RESULT_ANITA": 0.19760119940029985},
    {"TASK": "physical_state", "METRIC": "acc", "RESULT_LLAMA": 0.3235294117647059, "RESULT_ANITA": 0.31092436974789917},
    {"TASK": "sentipolc", "METRIC": "f1", "RESULT_LLAMA": 0.49026211686349636, "RESULT_ANITA": 0.5042007173387677},
    {"TASK": "squad_it", "METRIC": "squad_em", "RESULT_LLAMA": 0.6485740570377185, "RESULT_ANITA": 0.531607307136286},
    {"TASK": "story_class", "METRIC": "acc", "RESULT_LLAMA": 0.33146067415730335, "RESULT_ANITA": 0.6713483146067416},
    {"TASK": "traceIT", "METRIC": "acc", "RESULT_LLAMA": 0.7332155477031802, "RESULT_ANITA": 0.7031802120141343},
    {"TASK": "truthfulqa_gen_ita", "METRIC": "bleu_max", "RESULT_LLAMA": 59.40251227662129, "RESULT_ANITA": 9.876533274627027},
    {"TASK": "truthfulqa_mc1_ita", "METRIC": "acc", "RESULT_LLAMA": 0.35128518971848227, "RESULT_ANITA": 0.5238678090575275},
    {"TASK": "truthfulqa_mc2_ita", "METRIC": "acc", "RESULT_LLAMA": 0.5122116071934902, "RESULT_ANITA": 0.6794541687732483},
    {"TASK": "veryfIT_enriched", "METRIC": "acc", "RESULT_LLAMA": 0.48295454545454547, "RESULT_ANITA": 0.4318181818181818},
    {"TASK": "veryfIT_full", "METRIC": "acc", "RESULT_LLAMA": 0.4562097971301336, "RESULT_ANITA": 0.4082137555665512},
    {"TASK": "veryfIT_small", "METRIC": "acc", "RESULT_LLAMA": 0.48579545454545453, "RESULT_ANITA": 0.4318181818181818}
    ]
