[
{"TASK": "abricot_abs", "METRIC_NAME": "pearson", "RESULT_LLAMA_8": 0.2908569687822414, "RESULT_ANITA": 0.49656702564086047, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "abricot_inc", "METRIC_NAME": "pearson", "RESULT_LLAMA_8": 0.17995611105630827, "RESULT_ANITA": 0.13833157094574233, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "amelia-arg-component-fewshot", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.3294590036818332, "RESULT_ANITA": 0.3539600269076482, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "amelia-arg-component-zeroshot", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.21276489217697014, "RESULT_ANITA": 0.3696736469239985, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "amelia-arg-premisetype-fewshot", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.739723754147546, "RESULT_ANITA": 0.7953404032860343, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "amelia-arg-premisetype-zeroshot", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.39095695582205003, "RESULT_ANITA": 0.7115364327063769, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "amelia-arg-scheme-fewshot", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.35341596946742015, "RESULT_ANITA": 0.4967036183998685, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "amelia-arg-scheme-zeroshot", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.30847279538147243, "RESULT_ANITA": 0.36399881034088316, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ami_2020_aggressiveness", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.6043531519577608, "RESULT_ANITA": 0.48390898255900794, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ami_2020_misogyny", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.7264848403202169, "RESULT_ANITA": 0.7272727272727273, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "arc_challenge_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.4112627986348123, "RESULT_ANITA": 0.5341296928327645, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "arc_easy_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.640993265993266, "RESULT_ANITA": 0.7171717171717171, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "beep", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.6482876712328767, "RESULT_ANITA": 0.6243150684931507, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "belebele_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.8577777777777778, "RESULT_ANITA": 0.8377777777777777, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_agr1_0shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.10176824185248454, "RESULT_ANITA": 0.1405335507256354, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_agr1_1shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.25981139401067327, "RESULT_ANITA": 0.18409660865675453, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_agr2_0shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.10579686199272331, "RESULT_ANITA": 0.19820170728673997, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_agr2_1shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.2361151348809637, "RESULT_ANITA": 0.2988161930960832, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_caus1_0shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.05077655826700318, "RESULT_ANITA": 0.04763617241010421, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_caus1_1shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.130724815899494, "RESULT_ANITA": 0.08176935719678124, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_caus2_0shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.05696211378404919, "RESULT_ANITA": 0.06715288355895183, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_caus2_1shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.13108390415844468, "RESULT_ANITA": 0.12259124085699119, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_od1_0shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.06428726115074491, "RESULT_ANITA": 0.05625995517800767, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_od1_1shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.12549810096947103, "RESULT_ANITA": 0.08686878355214397, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_od2_0shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.06105883355813455, "RESULT_ANITA": 0.05662657526892521, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "blm_od2_1shots", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.1154221686931689, "RESULT_ANITA": 0.10120225478502334, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "conflict_detect", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.3723849372384937, "RESULT_ANITA": 0.34309623430962344, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ecwca-hint", "METRIC_NAME": "words_avg_f1", "RESULT_LLAMA_8": 0.4162932238081684, "RESULT_ANITA": 0.10082760014442343, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ecwca-no-hint", "METRIC_NAME": "words_avg_f1", "RESULT_LLAMA_8": 0.43453160370325206, "RESULT_ANITA": 0.07855228978056235, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "eureka_hints", "METRIC_NAME": "word_guesses_accuracy", "RESULT_LLAMA_8": 0.0714700978844334, "RESULT_ANITA": 0.0024733817492895486, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "eureka_original", "METRIC_NAME": "word_guesses_accuracy", "RESULT_LLAMA_8": 0.10153397537101387, "RESULT_ANITA": 0.0018260498894853176, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gattina-ansa", "METRIC_NAME": "sbert_score", "RESULT_LLAMA_8": 0.3264906958955771, "RESULT_ANITA": 0.17417554643821273, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gattina-galileo", "METRIC_NAME": "sbert_score", "RESULT_LLAMA_8": 0.21791279301643013, "RESULT_ANITA": 0.20502314949521763, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "geese_dummy", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.48625, "RESULT_ANITA": 0.50375, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "geese_human", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.5425, "RESULT_ANITA": 0.56375, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "geese_llama3", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.665, "RESULT_ANITA": 0.6225, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "geese_noexp", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.4625, "RESULT_ANITA": 0.37625, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gente_rephrasing", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.3100671140939597, "RESULT_ANITA": 0.3503355704697987, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_1_1", "METRIC_NAME": "bert_f1", "RESULT_LLAMA_8": 0.6407975602217856, "RESULT_ANITA": 0.4792027491203527, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_1_2", "METRIC_NAME": "bert_f1", "RESULT_LLAMA_8": 0.26739147770629834, "RESULT_ANITA": 0.287073515599058, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_2_1", "METRIC_NAME": "acc_gente", "RESULT_LLAMA_8": 0.6830357142857143, "RESULT_ANITA": 0.6651785714285714, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_2_2", "METRIC_NAME": "cwa", "RESULT_LLAMA_8": 52.7127569220316, "RESULT_ANITA": 53.89955268671079, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_2_3", "METRIC_NAME": "acc_gente", "RESULT_LLAMA_8": 0.31466666666666665, "RESULT_ANITA": 0.49866666666666665, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_3_1", "METRIC_NAME": "cwa", "RESULT_LLAMA_8": 39.311901930808, "RESULT_ANITA": 33.17988788856803, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "gfg_task_3_2", "METRIC_NAME": "acc_gente", "RESULT_LLAMA_8": 0.6066666666666667, "RESULT_ANITA": 0.566, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "haspeede2_hs", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.6991982842062379, "RESULT_ANITA": 0.6998010187451045, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "haspeede2_stereo", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.6037287968283951, "RESULT_ANITA": 0.624441393100974, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "hatecheck_ita", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.825468982535432, "RESULT_ANITA": 0.8117266439604165, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "hellaswag_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.4532961561441944, "RESULT_ANITA": 0.5105556662019518, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "honest_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.0, "RESULT_ANITA": 0.0, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "invalsi_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.7135183527305282, "RESULT_ANITA": 0.7090420769919427, "RESULT_MINERVA": 0.8871978513876455, "RESULT_LLAMA_70": 0.37958818263205013},
{"TASK": "invalsi_ita_binarie", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.6071428571428571, "RESULT_ANITA": 0.65, "RESULT_MINERVA": 0.7428571428571429, "RESULT_LLAMA_70": 0.5928571428571429},
{"TASK": "invalsi_ita_multipla", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.7287615148413511, "RESULT_ANITA": 0.7175025588536336, "RESULT_MINERVA": 0.9078812691914022, "RESULT_LLAMA_70": 0.3490276356192426},
{"TASK": "invalsi_mate", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.5075, "RESULT_ANITA": 0.4725, "RESULT_MINERVA": 0.7175, "RESULT_LLAMA_70": 0.335},
{"TASK": "invalsi_mate_multipla", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.45491803278688525, "RESULT_ANITA": 0.4139344262295082, "RESULT_MINERVA": 0.7049180327868853, "RESULT_LLAMA_70": 0.30327868852459017},
{"TASK": "invalsi_mate_numero", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.5882352941176471, "RESULT_ANITA": 0.5392156862745098, "RESULT_MINERVA": 0.7843137254901961, "RESULT_LLAMA_70": 0.27450980392156865},
{"TASK": "invalsi_mate_verofalso", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.5925925925925926, "RESULT_ANITA": 0.6111111111111112, "RESULT_MINERVA": 0.6481481481481481, "RESULT_LLAMA_70": 0.5925925925925926},
{"TASK": "ironita_irony", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.6741186970102633, "RESULT_ANITA": 0.6869456865349934, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ironita_sarcasm", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.5178314988006253, "RESULT_ANITA": 0.4641951625148186, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ita-sense-gen-no-translation", "METRIC_NAME": "rougeBertScore", "RESULT_LLAMA_8": 0.31921862236515036, "RESULT_ANITA": 0.25854083584126464, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ita-sense-gen-with-translation", "METRIC_NAME": "rougeBertScore", "RESULT_LLAMA_8": 0.3192784120872682, "RESULT_ANITA": 0.2630987442843378, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ita-sense-ml-no-translation", "METRIC_NAME": "extract_answer", "RESULT_LLAMA_8": 0.41268803139306737, "RESULT_ANITA": 0.5120994113799869, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ita-sense-ml-with-translation", "METRIC_NAME": "extract_answer", "RESULT_LLAMA_8": 0.3856280855732309, "RESULT_ANITA": 0.4750411409764125, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "ita-text-to-sql", "METRIC_NAME": "execution_accuracy", "RESULT_LLAMA_8": 0.2722772277227723, "RESULT_ANITA": 0.28217821782178215, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "itacola", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.8246153846153846, "RESULT_ANITA": 0.6892307692307692, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "multi-it-a", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.6465721040189125, "RESULT_ANITA": 0.6211583924349882, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "multi-it-c", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.6623020762454714, "RESULT_ANITA": 0.6280964378321717, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "news_sum_fanpage", "METRIC_NAME": "rouge1", "RESULT_LLAMA_8": 0.32841168208870886, "RESULT_ANITA": 0.30181000742312586, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "news_sum_ilpost", "METRIC_NAME": "rouge1", "RESULT_LLAMA_8": 0.3200355367367411, "RESULT_ANITA": 0.28636010182549587, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "pejorativITy-misoginy", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.44191206030330804, "RESULT_ANITA": 0.6534816634046885, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "pejorativITy-misoginy-context", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.7888466104387166, "RESULT_ANITA": 0.75387691923125, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "pejorativITy-standard", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.3871185117651902, "RESULT_ANITA": 0.35928867967702915, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "perse_task_0", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.4953869281153722, "RESULT_ANITA": 0.3238903867047604, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "perse_task_1", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.4973010010528603, "RESULT_ANITA": 0.24787574234810417, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "perse_task_2", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.49703006640638037, "RESULT_ANITA": 0.26859912052409585, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "perse_task_3", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.49607149132715816, "RESULT_ANITA": 0.19760119940029985, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "physical_state", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.3235294117647059, "RESULT_ANITA": 0.31092436974789917, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "sentipolc", "METRIC_NAME": "f1", "RESULT_LLAMA_8": 0.49026211686349636, "RESULT_ANITA": 0.5042007173387677, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "squad_it", "METRIC_NAME": "squad_em", "RESULT_LLAMA_8": 0.6485740570377185, "RESULT_ANITA": 0.531607307136286, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "story_class", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.33146067415730335, "RESULT_ANITA": 0.6713483146067416, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "traceIT", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.7332155477031802, "RESULT_ANITA": 0.7031802120141343, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "truthfulqa_gen_ita", "METRIC_NAME": "bleu_max", "RESULT_LLAMA_8": 59.40251227662129, "RESULT_ANITA": 9.876533274627027, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "truthfulqa_mc1_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.35128518971848227, "RESULT_ANITA": 0.5238678090575275, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "truthfulqa_mc2_ita", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.5122116071934902, "RESULT_ANITA": 0.6794541687732483, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "veryfIT_enriched", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.48295454545454547, "RESULT_ANITA": 0.4318181818181818, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "veryfIT_full", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.4562097971301336, "RESULT_ANITA": 0.4082137555665512, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""},
{"TASK": "veryfIT_small", "METRIC_NAME": "acc", "RESULT_LLAMA_8": 0.48579545454545453, "RESULT_ANITA": 0.4318181818181818, "RESULT_MINERVA": "", "RESULT_LLAMA_70": ""}
]
